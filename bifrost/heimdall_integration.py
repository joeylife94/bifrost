"""Kafka Integration Service - Heimdall ì—°ë™ í•µì‹¬ ë¡œì§"""

import time
from decimal import Decimal
from typing import Optional

from bifrost.kafka_events import (
    AnalysisRequestEvent,
    AnalysisResultEvent,
    AnalysisResultData
)
from bifrost.kafka_producer import KafkaProducerManager
from bifrost.ollama import OllamaClient
from bifrost.bedrock import BedrockClient, is_bedrock_available
from bifrost.preprocessor import LogPreprocessor
from bifrost.database import get_database
from bifrost.logger import logger


# Master Prompt (ê¸°ì¡´ ì‚¬ìš© ì¤‘ì¸ í”„ë¡¬í”„íŠ¸)
MASTER_PROMPT = """ë‹¹ì‹ ì€ ì „ë¬¸ MLOps SREì…ë‹ˆë‹¤. ì•„ë˜ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ê³  ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

## ğŸ“Š ìš”ì•½
ë¡œê·¸ì˜ í•µì‹¬ ë‚´ìš©ì„ 3-5ì¤„ë¡œ ìš”ì•½

## ğŸ” ì£¼ìš” ì´ìŠˆ
- ë°œê²¬ëœ ì—ëŸ¬ë‚˜ ê²½ê³ 
- ì¤‘ìš”í•œ íŒ¨í„´ì´ë‚˜ ì´ìƒ ì§•í›„

## ğŸ’¡ ì œì•ˆì‚¬í•­
- ë¬¸ì œ í•´ê²° ë°©ë²•
- ê°œì„  ë°©í–¥

---
ë¡œê·¸:
{log_content}
"""


class HeimdallIntegrationService:
    """Heimdallê³¼ì˜ Kafka ê¸°ë°˜ í†µí•© ì„œë¹„ìŠ¤"""
    
    def __init__(self, config: dict, producer_manager: KafkaProducerManager):
        self.config = config
        self.producer_manager = producer_manager
        self.preprocessor = LogPreprocessor()
        self.db = get_database()
    
    async def process_analysis_request(self, event: AnalysisRequestEvent):
        """
        ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ - Kafka Consumerê°€ í˜¸ì¶œ
        
        Args:
            event: Heimdallë¡œë¶€í„° ë°›ì€ ë¶„ì„ ìš”ì²­ ì´ë²¤íŠ¸
        """
        start_time = time.time()
        
        logger.info(
            f"Processing analysis request from Heimdall",
            request_id=event.request_id,
            log_id=event.log_id,
            service_name=event.service_name,
            environment=event.environment,
            priority=event.priority
        )
        
        try:
            # 1. ë¡œê·¸ ì „ì²˜ë¦¬
            processed_log = self.preprocessor.process(event.log_content)
            
            # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = MASTER_PROMPT.format(log_content=processed_log)
            
            # 3. AI ë¶„ì„ ìˆ˜í–‰
            analysis_response = await self._analyze_with_ai(
                prompt=prompt,
                source=self._get_source_from_config()
            )
            
            # 4. ë¶„ì„ ê²°ê³¼ ì €ì¥ (Bifrost DB)
            bifrost_analysis_id = self._save_analysis_to_db(
                event=event,
                response=analysis_response,
                duration=time.time() - start_time
            )
            
            # 5. ë¶„ì„ ê²°ê³¼ë¥¼ AnalysisResultDataë¡œ ë³€í™˜
            result_data = self._parse_analysis_response(
                response=analysis_response["response"],
                confidence=0.85  # TODO: ëª¨ë¸ì—ì„œ confidence ì¶”ì¶œ
            )
            
            # 6. Kafkaë¡œ ê²°ê³¼ ë°œí–‰ (Heimdallë¡œ ì „ì†¡)
            result_event = AnalysisResultEvent(
                request_id=event.request_id,
                correlation_id=event.correlation_id,
                log_id=event.log_id,
                analysis_result=result_data,
                bifrost_analysis_id=bifrost_analysis_id,
                model=analysis_response["metadata"]["model"],
                duration_seconds=Decimal(str(round(time.time() - start_time, 2)))
            )
            
            success = await self.producer_manager.send_result(result_event)
            
            if success:
                logger.info(
                    f"Analysis completed and sent to Heimdall",
                    request_id=event.request_id,
                    log_id=event.log_id,
                    bifrost_analysis_id=bifrost_analysis_id,
                    duration_seconds=result_event.duration_seconds
                )
            else:
                logger.error(
                    f"Failed to send analysis result to Heimdall",
                    request_id=event.request_id,
                    log_id=event.log_id
                )
            
        except Exception as e:
            logger.error(
                f"Error processing analysis request",
                request_id=event.request_id,
                log_id=event.log_id,
                error=str(e),
                exc_info=True
            )
            raise
    
    async def _analyze_with_ai(self, prompt: str, source: str) -> dict:
        """AI ëª¨ë¸ë¡œ ë¡œê·¸ ë¶„ì„"""
        if source == "local":
            client = OllamaClient(
                url=self.config.get("ollama", {}).get("url", "http://localhost:11434"),
                model=self.config.get("ollama", {}).get("model", "mistral")
            )
            result = client.analyze(prompt, stream=False)
        elif source == "cloud":
            if not is_bedrock_available():
                raise RuntimeError("Bedrock not available (boto3 not installed)")
            
            client = BedrockClient(
                region=self.config.get("bedrock", {}).get("region", "us-east-1"),
                model_id=self.config.get("bedrock", {}).get(
                    "model", "anthropic.claude-3-sonnet-20240229-v1:0"
                )
            )
            result = client.analyze(prompt)
        else:
            raise ValueError(f"Invalid source: {source}")
        
        return result
    
    def _save_analysis_to_db(
        self,
        event: AnalysisRequestEvent,
        response: dict,
        duration: float
    ) -> int:
        """ë¶„ì„ ê²°ê³¼ë¥¼ Bifrost DBì— ì €ì¥"""
        analysis_id = self.db.save_analysis(
            source=self._get_source_from_config(),
            model=response["metadata"]["model"],
            log_content=event.log_content,
            response=response["response"],
            duration=duration,
            tags=[
                f"heimdall:log_id:{event.log_id}",
                f"service:{event.service_name}",
                f"env:{event.environment}",
                f"priority:{event.priority}"
            ],
            service_name=event.service_name,
            environment=event.environment,
            tokens_used=response["metadata"].get("usage", {}).get("total_tokens"),
            status="completed"
        )
        
        return analysis_id
    
    def _parse_analysis_response(self, response: str, confidence: float) -> AnalysisResultData:
        """
        AI ì‘ë‹µì„ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
        
        TODO: ë” ì •êµí•œ íŒŒì‹± ë¡œì§ êµ¬í˜„ (ë§ˆí¬ë‹¤ìš´ íŒŒì‹±, ì„¹ì…˜ ì¶”ì¶œ ë“±)
        """
        lines = response.strip().split('\n')
        
        summary = ""
        root_cause = ""
        recommendation = ""
        severity = "MEDIUM"
        
        current_section = None
        
        for line in lines:
            line = line.strip()
            
            if "ìš”ì•½" in line or "Summary" in line:
                current_section = "summary"
            elif "ì£¼ìš” ì´ìŠˆ" in line or "ì´ìŠˆ" in line or "Issue" in line:
                current_section = "root_cause"
            elif "ì œì•ˆ" in line or "ê¶Œì¥" in line or "Recommendation" in line:
                current_section = "recommendation"
            elif line and not line.startswith('#'):
                if current_section == "summary":
                    summary += line + " "
                elif current_section == "root_cause":
                    root_cause += line + " "
                elif current_section == "recommendation":
                    recommendation += line + " "
        
        # ì‹¬ê°ë„ ì¶”ë¡ 
        if "CRITICAL" in response.upper() or "FATAL" in response.upper():
            severity = "CRITICAL"
        elif "ERROR" in response.upper() or "ì‹¤íŒ¨" in response:
            severity = "HIGH"
        elif "WARN" in response.upper() or "ê²½ê³ " in response:
            severity = "MEDIUM"
        else:
            severity = "LOW"
        
        return AnalysisResultData(
            summary=summary.strip() or "ë¶„ì„ ìš”ì•½ ì •ë³´ ì—†ìŒ",
            root_cause=root_cause.strip() or "ê·¼ë³¸ ì›ì¸ ë¶„ì„ ì¤‘",
            recommendation=recommendation.strip() or "ê¶Œì¥ì‚¬í•­ ë¶„ì„ ì¤‘",
            severity=severity,
            confidence=Decimal(str(confidence))
        )
    
    def _get_source_from_config(self) -> str:
        """ì„¤ì •ì—ì„œ AI ì†ŒìŠ¤ ê²°ì •"""
        return self.config.get("heimdall", {}).get("ai_source", "local")
